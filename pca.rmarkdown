---
title: "PCA"
execute:
  warning: false
  message: false
knitr:
  opts_chunk: 
    collapse: true
    comment: "#>"
format:
  html:
    toc: true
    html-math-method: katex
    code-fold: true
    css: styles.css
editor_options: 
  chunk_output_type: console
---


## Introduction

Principal Componet Analysis (PCA) is a statistical technique that simplifies complex data by reducing dimensions. PCA is like finding the main themes in a complex book. As for the crime data, there are 52 predictor variables, and it can be challenging to see the bigger picture. PCA helps us identify the most important patterns or themes in this data, making it easier to understand and act upon.

## Pre-Process Data

### Set Up

Similar to how we pre-processed data for kriging, we will pre-process the data. Ultimately, this step will result in two dataframes: one containing predictors and location (`asb_pred`) and the other for the outcome variable and location (`asb_outcome`).


```{r}
rm(list = ls())
#--Install / load packages
pacman::p_load(sp, sf, data.table, rio, here, leaflet, gstat, tidyverse, Metrics, scales, corrr, ggcorrplot, FactoMineR, factoextra, corrplot)

#--Import street-level asb data
asb <- import(here("arc_lbb_website", "3_output", "asb_with_nearest_distances.csv"))

#--Calculate count of crimes per location coordinate
asb_count <- asb |> 
    group_by(location.latitude, location.longitude) |>
    count() |> 
    ungroup() |> 
    inner_join(asb, by = c('location.latitude', 'location.longitude')) |> 
    distinct(location.latitude, location.longitude, .keep_all = TRUE) |>
    group_by(location.latitude, location.longitude) |>
    mutate(location_id = cur_group_id()) |>
    ungroup()

#--Rename columns 
names(asb_count)[grepl('longitude', names(asb_count))] <- 'x' 
names(asb_count)[grepl('latitude', names(asb_count))] <- 'y' 

#--Convert dataframe to sf object and reproject to OSGB36
asb_count_sf <- asb_count |> 
    st_as_sf(coords = c('x', 'y'), crs = 4326) 

#--Get coordinates
asb_count_sf <- asb_count_sf |>
    mutate(x = st_coordinates(asb_count_sf)[, 1],
           y = st_coordinates(asb_count_sf)[, 2])

#--Change the sf back to df
asb_count <- st_drop_geometry(asb_count_sf)

#--Select only numeric columns
asb_x <- asb_count |> select(x, y, starts_with('d'))
asb_y <- asb_count |> select(x, y, n)
```


### Split Data into Test & Train Sets

```{r}
#--Create random indices
total_rows <- nrow(asb_count)
sample_size <- round(total_rows * 0.75)

set.seed(1234)
random_indices <- sample(1:total_rows, sample_size, replace = FALSE)

#--Create test sets using the random indices
x_train <- asb_x[dimnames(asb_x)[[1]] %in% random_indices,] |>
    mutate(across(where(is.numeric), ~round(.x, 2)))

y_train <- asb_y[dimnames(asb_y)[[1]] %in% random_indices,]|>
    mutate(across(where(is.numeric), ~round(.x, 2)))

#--Create training sets by excluding the indices used for the test set
x_test <- asb_x[!dimnames(asb_x)[[1]] %in% random_indices,]|>
    mutate(across(where(is.numeric), ~round(.x, 2)))

y_test <- asb_y[!dimnames(asb_y)[[1]] %in% random_indices,] |>
    mutate(across(where(is.numeric), ~round(.x, 2)))
```


## Run PCA 

```{r}
#--Apply PCA
x_train_pca <- FactoMineR::PCA(x_train[-c(1,2)], graph = FALSE, scale.unit = TRUE)

#--Check cumulative percentage of variance
x_train_pca$eig
```


Component 1 to 7 explains around 70% of total variance. Hence, we will specify 7 as the number of components to keep.


```{r}
#--Apply PCA again with the selected number of components
x_train_pca <- PCA(x_train[-c(1,2)], graph = FALSE, scale.unit = TRUE, ncp = 7)

#--Predict 
x_train_pred <- FactoMineR::predict.PCA(x_train_pca, x_train[-c(1,2)])
x_test_pred <- FactoMineR::predict.PCA(x_train_pca, x_test[-c(1,2)])

#--Extract PCA-transformed data
x_train_pred_df <- as.data.frame(x_train_pred$coord)
x_test_pred_df <- as.data.frame(x_test_pred$coord)

#--Add coordinates to the PCA-transformed data
x_train_pred_df <- cbind(x_train_pred_df, x = x_train$x, y = x_train$y)
x_test_pred_df <- cbind(x_test_pred_df, x = x_test$x, y = x_test$y)
```


## Understand Output

```{r}
var <- get_pca_var(x_train_pca)

#--Quality of representation (how well the variable is represnted by PC)
#---View cos2 value in each dimension
var$cos2[,1] |> sort(TRUE) |> head(10)  
var$cos2[,2] |> sort(TRUE) |> head(10) 
var$cos2[,3] |> sort(TRUE) |> head(10)
var$cos2[,4] |> sort(TRUE) |> head(10)
var$cos2[,5] |> sort(TRUE) |> head(10)

#--Contribution (how much each variable contributes to the construction of a principal component)
#---View contribution values
var$contrib[,1] |> sort(TRUE) |> head(10) 
var$contrib[,2] |> sort(TRUE) |> head(10) 
var$contrib[,3] |> sort(TRUE) |> head(10)
var$contrib[,4] |> sort(TRUE) |> head(10)
var$contrib[,5] |> sort(TRUE) |> head(10)
```
